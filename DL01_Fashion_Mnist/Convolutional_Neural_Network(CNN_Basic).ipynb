{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional_Neural_Network(CNN_Basic).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2PDc5BGvbjl"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WJQqna1hxAXO",
        "outputId": "3a8780f4-4c8d-4ec9-bc7c-408674e79622"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlnELXYUv67U"
      },
      "source": [
        "# Before feeding the images from training set to the NN's input, \n",
        "# we need to perform certain transformations and scalling as a prequisite.\n",
        "# below we create a obj of ImageDataGenerator() for training set,\n",
        "# and in its constructor we specify the attrs to implement transformations. \n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255, # Scale values btw 1 and 255\n",
        "        shear_range=0.2, \n",
        "        zoom_range=0.2, \n",
        "        horizontal_flip=True)\n",
        "\n",
        "# below we use flow_from_directory() to import our  training dataset from out pc. \n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        'my trainset path',\n",
        "        target_size=(64, 64), # (64,64) specifies target ImageSize after performing Image Preprocessing. \n",
        "        batch_size=32, # specifies that , take 32 images in 1 batch.\n",
        "        class_mode='binary') # specifies the mode of classification.\n",
        "# --x training set x--"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BifCwZWB33Zk"
      },
      "source": [
        "# below we create a obj of ImageDataGenerator() for testing set,\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# below we use flow_from_directory() to import our  testing dataset from out pc. \n",
        "testing_set = test_datagen.flow_from_directory(\n",
        "        'my testing path',\n",
        "        target_size=(64, 64), # should be same as that of training set target preprocessed images.\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "# --x testing set x--"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBaIwMhf34gx"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VlmdIat3_Sg"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, # No of filter/feature_detector = 32  \n",
        "                               kernel_size=3, # feature map of size: 3*3\n",
        "                               activation='relu',\n",
        "                               input_shape=[64, 64, 3]) # 3 stands for colored image.\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2Ku9Q2o4sbK"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, # specifies the moving window of 2*2\n",
        "                                  strides=2) # shift by 2 cols.\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSS1RE4H47b4"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvj4h2_s489M"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten()) # generate a column vector that acts as an input for ann"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5NYTAk24_hO"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128,\n",
        "                              activation='relu')) # no of neurons=128 in hidden layer of ann"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BWGozqN5RSp"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, # one neuron is suffieicent for binary classification\n",
        "                              activation='sigmoid')) # 'sigmoid' for probability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8duydaeu6YJA"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFYMdvle6ZbI"
      },
      "source": [
        "cnn.fit(x = training_set,\n",
        "        validation_data = testing_set,\n",
        "        epochs = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc70eXS9Lods"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64)) # for loading single prediction image\n",
        "test_image = image.img_to_array(test_image) # converting image to numpy array\n",
        "test_image = np.expand_dims(test_image, axis = 0) # dividing into batch\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMeYw-ZeLqun"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}